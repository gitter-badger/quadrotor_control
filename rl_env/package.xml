<package>
  <name>rl_env</name>
  <version>0.0.1</version>
  <description>
    Provides a set of reinforcement learning environments (gridworlds, mountain car, cart pole, stock trading, robot car simulations) for RL agents to learn in.
  </description>
  <maintainer email="kunalgrover05@gmail.com">Kunal Grover</maintainer>

  <license>BSD</license>
  <author email="kunalgrover05@gmail.com">Kunal Grover</author>

  <!-- Dependencies which this package needs to build itself. -->
  <buildtool_depend>catkin</buildtool_depend>

  <!-- Dependencies needed to compile this package. -->
  <build_depend>std_msgs</build_depend>
  <build_depend>roscpp</build_depend>
  <build_depend>rl_msgs</build_depend>
  <build_depend>tf</build_depend>
  <build_depend>rl_common</build_depend>
  <build_depend>hector_uav_msgs</build_depend>

  <!-- Dependencies needed after this package is compiled. -->
  <run_depend>std_msgs</run_depend>
  <run_depend>roscpp</run_depend>
  <run_depend>rl_msgs</run_depend>
  <run_depend>tf</run_depend>
  <run_depend>rl_common</run_depend>
  <run_depend>hector_uav_msgs</run_depend>

  <!-- Dependencies needed only for running tests. -->

  <export>
    <cpp cflags="-I${prefix}/include"
         lflags="-L${prefix}/lib -Wl,-rpath,${prefix}/lib"/>
  </export>
</package>

